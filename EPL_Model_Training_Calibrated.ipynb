{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8afbf58",
   "metadata": {},
   "source": [
    "# ðŸ§  EPL Model Training with Calibration\n",
    "This notebook trains calibrated models for Over 1.5, Over 2.5, BTTS, Match Result, and Corners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addee776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c27aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "data = pd.read_excel(\"epl_team_form_features_updated.xlsx\")\n",
    "\n",
    "# Create binary labels and numeric targets\n",
    "data['Over_1.5'] = (data['FTHG'] + data['FTAG'] >= 2).astype(int)\n",
    "data['Over_2.5'] = (data['FTHG'] + data['FTAG'] >= 3).astype(int)\n",
    "data['BTTS_Label'] = ((data['FTHG'] > 0) & (data['FTAG'] > 0)).astype(int)\n",
    "data['Total_Corners'] = data['HC'] + data['AC']\n",
    "data['Result'] = data['FTR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd091a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select features\n",
    "feature_cols = [col for col in data.columns if col.startswith(\"Home_\") or col.startswith(\"Away_\")]\n",
    "X = data[feature_cols].fillna(0)\n",
    "y_15 = data['Over_1.5']\n",
    "y_25 = data['Over_2.5']\n",
    "y_btts = data['BTTS_Label']\n",
    "y_corners = data['Total_Corners']\n",
    "le_result = LabelEncoder()\n",
    "y_result = le_result.fit_transform(data['Result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daceae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train_15, y_test_15 = train_test_split(X_scaled, y_15, test_size=0.2, random_state=42)\n",
    "_, _, y_train_25, y_test_25 = train_test_split(X_scaled, y_25, test_size=0.2, random_state=42)\n",
    "_, _, y_train_btts, y_test_btts = train_test_split(X_scaled, y_btts, test_size=0.2, random_state=42)\n",
    "_, _, y_train_corners, y_test_corners = train_test_split(X_scaled, y_corners, test_size=0.2, random_state=42)\n",
    "_, _, y_train_result, y_test_result = train_test_split(X_scaled, y_result, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242115ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train calibrated models\n",
    "lr_15 = CalibratedClassifierCV(LogisticRegression(max_iter=200)).fit(X_train, y_train_15)\n",
    "lr_25 = CalibratedClassifierCV(LogisticRegression(max_iter=200)).fit(X_train, y_train_25)\n",
    "rf_btts = CalibratedClassifierCV(RandomForestClassifier(n_estimators=100, random_state=42)).fit(X_train, y_train_btts)\n",
    "rf_result = CalibratedClassifierCV(RandomForestClassifier(n_estimators=100, random_state=42)).fit(X_train, y_train_result)\n",
    "rf_corners = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_train, y_train_corners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save models\n",
    "joblib.dump(lr_15, 'lr_model_over_1_5_calibrated.joblib')\n",
    "joblib.dump(lr_25, 'lr_model_over_2_5_calibrated.joblib')\n",
    "joblib.dump(rf_btts, 'btts_model_calibrated.joblib')\n",
    "joblib.dump(rf_result, 'win_model_calibrated.joblib')\n",
    "joblib.dump(rf_corners, 'corner_model.joblib')\n",
    "joblib.dump(scaler, 'scaler_model.joblib')\n",
    "\n",
    "print(\"âœ… All models trained and saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
